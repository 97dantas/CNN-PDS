{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-08 08:15:16.474027: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-08 08:15:16.474046: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-11-08 08:15:17.708555: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-08 08:15:17.708591: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-08 08:15:17.708625: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (israel-Nitro-AN515-51): /proc/driver/nvidia/version does not exist\n",
      "2021-11-08 08:15:17.708819: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "\n",
    "classificator = Sequential()\n",
    "classificator.add(Conv2D(32, (3,3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "classificator.add(BatchNormalization())\n",
    "classificator.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "classificator.add(Conv2D(32, (3,3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "classificator.add(BatchNormalization())\n",
    "classificator.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "classificator.add(Conv2D(32, (3,3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "classificator.add(BatchNormalization())\n",
    "classificator.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "\n",
    "classificator.add(Flatten())\n",
    "\n",
    "classificator.add(Dense(units = 256, activation = 'relu'))\n",
    "classificator.add(Dropout(0.3))\n",
    "classificator.add(Dense(units = 128, activation = 'relu'))\n",
    "classificator.add(Dropout(0.3))\n",
    "classificator.add(Dense(units = 64, activation = 'relu'))\n",
    "classificator.add(Dropout(0.3))\n",
    "classificator.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "classificator.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "training_generator = ImageDataGenerator(rescale = 1./255)\n",
    "                                        #  rotation_range = 7,\n",
    "                                        #  horizontal_flip = True,\n",
    "                                        #  shear_range = 0.2,\n",
    "                                        #  height_shift_range = 0.07,\n",
    "                                        #  zoom_range = 0.2)\n",
    "                                         \n",
    "test_generator = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 598 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n",
      "{'capela_anomalia': 0, 'capela_normal': 1}\n",
      "{'capela_anomalia': 0, 'capela_normal': 1}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 30\n",
    "training_base = training_generator.flow_from_directory('capela/dataset/training',\n",
    "                                                           target_size = (64, 64),\n",
    "                                                           batch_size = batch_size,\n",
    "                                                           class_mode = 'binary')\n",
    "\n",
    "test_base = test_generator.flow_from_directory('capela/dataset/validation',                                               \n",
    "                                               target_size = (64, 64),\n",
    "                                               batch_size = batch_size,\n",
    "                                               class_mode = 'binary')\n",
    "print(training_base.class_indices)\n",
    "print(test_base.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/israel/.local/lib/python3.8/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2021-11-08 08:11:10.038560: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - ETA: 0s - loss: 0.9871 - accuracy: 0.5705WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n",
      "10/10 [==============================] - 3s 271ms/step - loss: 0.9871 - accuracy: 0.5705 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.9805 - accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 1s 144ms/step - loss: 0.8183 - accuracy: 0.5067\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 1s 142ms/step - loss: 0.6765 - accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 2s 169ms/step - loss: 0.5941 - accuracy: 0.7167\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 2s 164ms/step - loss: 0.3811 - accuracy: 0.8300\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 2s 150ms/step - loss: 0.1945 - accuracy: 0.9329\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 2s 158ms/step - loss: 0.0786 - accuracy: 0.9667\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 2s 164ms/step - loss: 0.0840 - accuracy: 0.9767\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 2s 158ms/step - loss: 0.0964 - accuracy: 0.9698\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 2s 154ms/step - loss: 0.0898 - accuracy: 0.9667\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 2s 155ms/step - loss: 0.0492 - accuracy: 0.9800\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 2s 157ms/step - loss: 0.0369 - accuracy: 0.9800\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 2s 160ms/step - loss: 0.0056 - accuracy: 0.9966\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 2s 161ms/step - loss: 0.0053 - accuracy: 0.9967\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 2s 178ms/step - loss: 0.0103 - accuracy: 0.9933\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 2s 164ms/step - loss: 0.0069 - accuracy: 0.9967\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0057 - accuracy: 0.9967\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0257 - accuracy: 0.9933\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 2s 159ms/step - loss: 0.0290 - accuracy: 0.9900\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 2s 157ms/step - loss: 0.0095 - accuracy: 0.9967\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 2s 177ms/step - loss: 0.0055 - accuracy: 0.9966\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 2s 171ms/step - loss: 0.0143 - accuracy: 0.9933\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 2s 155ms/step - loss: 0.0260 - accuracy: 0.9967\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 2s 159ms/step - loss: 0.0365 - accuracy: 0.9933\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 2s 179ms/step - loss: 0.0139 - accuracy: 0.9933\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 2s 158ms/step - loss: 0.0253 - accuracy: 0.9900\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 2s 162ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 2s 166ms/step - loss: 0.0033 - accuracy: 0.9967\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 2s 170ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 2s 180ms/step - loss: 6.2799e-04 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 2s 154ms/step - loss: 8.8033e-04 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 2s 156ms/step - loss: 0.0032 - accuracy: 0.9966\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0246 - accuracy: 0.9933\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 0.0064 - accuracy: 0.9967\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0108 - accuracy: 0.9966\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 2s 161ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 2s 178ms/step - loss: 0.0043 - accuracy: 0.9966\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 2s 183ms/step - loss: 0.0097 - accuracy: 0.9966\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 2s 181ms/step - loss: 0.0045 - accuracy: 0.9966\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 0.0631 - accuracy: 0.9933\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 2s 154ms/step - loss: 4.2279e-04 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 2s 149ms/step - loss: 0.0493 - accuracy: 0.9966\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 2s 155ms/step - loss: 0.0179 - accuracy: 0.9900\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 2s 169ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 2s 155ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 2s 149ms/step - loss: 0.0138 - accuracy: 0.9933\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 1.3697e-04 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 1.2967e-04 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 2s 150ms/step - loss: 0.0076 - accuracy: 0.9966\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 2s 154ms/step - loss: 5.1661e-04 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 2s 154ms/step - loss: 9.7109e-04 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 1.0936e-04 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 3.3208e-05 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 2s 150ms/step - loss: 3.1125e-05 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 2s 149ms/step - loss: 3.9996e-05 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 2s 154ms/step - loss: 2.5848e-04 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 2s 166ms/step - loss: 6.7013e-05 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 2s 180ms/step - loss: 4.0759e-04 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 2s 150ms/step - loss: 2.3563e-04 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 2s 158ms/step - loss: 2.0249e-06 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 2s 149ms/step - loss: 1.7285e-05 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 8.3682e-05 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 7.7416e-06 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 2s 154ms/step - loss: 1.6985e-05 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 3.9871e-05 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 2s 150ms/step - loss: 4.0174e-06 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 2s 155ms/step - loss: 1.4926e-05 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 2.2059e-05 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 2s 154ms/step - loss: 3.2534e-05 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 2s 155ms/step - loss: 2.4009e-06 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 5.6190e-05 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 2s 154ms/step - loss: 1.5500e-05 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 2s 162ms/step - loss: 1.4112e-05 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 2s 180ms/step - loss: 2.4926e-05 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 2s 160ms/step - loss: 2.5656e-05 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 2.1068e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 2s 166ms/step - loss: 1.8092e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 2s 175ms/step - loss: 5.7069e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 2s 154ms/step - loss: 1.6695e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 2s 150ms/step - loss: 6.0622e-05 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 1.1371e-05 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 2s 149ms/step - loss: 7.1299e-05 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 2s 153ms/step - loss: 8.2904e-05 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 4.5019e-06 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 1.9571e-05 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 2s 165ms/step - loss: 9.1662e-06 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 2s 181ms/step - loss: 1.4647e-05 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 2s 150ms/step - loss: 3.4831e-06 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 1.0173e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 4.8888e-05 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 2s 155ms/step - loss: 7.6635e-05 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 2.0539e-05 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 2s 151ms/step - loss: 6.1043e-05 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 2s 159ms/step - loss: 7.2467e-06 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 2s 178ms/step - loss: 2.2815e-05 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 8.0215e-05 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 2s 152ms/step - loss: 2.5471e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc504047d30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificator.fit_generator(training_base, steps_per_epoch = 10,\n",
    "                            epochs = 100, validation_data = test_base,\n",
    "                            validation_steps = 10)\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificator.save('capela/weights/weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificator.load_weights('capela/weights/weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.5312278e-10]]\n",
      "[[False]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'capela_anomalia': 0, 'capela_normal': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagem_teste = image.load_img('capela/dataset/test/capela_anomalia/capela_anomalia.105.png',\n",
    "                              target_size = (64,64))\n",
    "\n",
    "imagem_teste = image.img_to_array(imagem_teste)\n",
    "imagem_teste /= 255\n",
    "imagem_teste = np.expand_dims(imagem_teste, axis = 0)\n",
    "previsao = classificator.predict(imagem_teste)\n",
    "print(previsao)\n",
    "previsao = (previsao > 0.5)\n",
    "print(previsao)\n",
    "training_base.class_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/israel/.local/lib/python3.8/site-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'capela_anomalia': 0, 'capela_normal': 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "validation_generator1 = ImageDataGenerator(rescale = 1./255)\n",
    "base_validation1 = validation = validation_generator1.flow_from_directory('capela/dataset/test/',\n",
    "                                               target_size = (64, 64),\n",
    "                                               batch_size = 10,\n",
    "                                               class_mode = 'binary')\n",
    "\n",
    "y_pred = classificator.predict_generator(base_validation1, steps = 10)\n",
    "base_validation1.class_indices\n",
    "\n",
    "validation_generator2 = ImageDataGenerator(rescale = 1./255)\n",
    "base_validation2 = validation = validation_generator2.flow_from_directory('capela/dataset/test2/',\n",
    "                                               target_size = (64, 64),\n",
    "                                               batch_size = 10,\n",
    "                                               class_mode = 'binary')\n",
    "\n",
    "y_pred2 = classificator.predict_generator(base_validation2, steps = 10)\n",
    "base_validation2.class_indices\n",
    "# {'capela_anomalia': 0, 'capela_normal': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.squeeze(np.asarray(y_pred))\n",
    "for x in y_pred:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# [50]\n",
    "\n",
    "y_pred = np.around(np.squeeze(np.asarray(y_pred)))\n",
    "y_pred2 = np.around(np.squeeze(np.asarray(y_pred2)))\n",
    "\n",
    "# y_pred = np.squeeze(np.asarray(y_pred))\n",
    "# y_pred2 = np.squeeze(np.asarray(y_pred2))\n",
    "\n",
    "y_p = np.concatenate((y_pred, y_pred2))\n",
    "y_classes = np.concatenate((base_validation1.classes, base_validation2.classes))\n",
    "\n",
    "print(y_classes)\n",
    "print(y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100   0]\n",
      " [  0 100]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "matrix = confusion_matrix(y_classes, y_p)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "capela_anomalia       1.00      1.00      1.00       100\n",
      "  capela_normal       1.00      1.00      1.00       100\n",
      "\n",
      "       accuracy                           1.00       200\n",
      "      macro avg       1.00      1.00      1.00       200\n",
      "   weighted avg       1.00      1.00      1.00       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = metrics.classification_report(y_classes, y_p, target_names=base_validation1.class_indices)\n",
    "print(report)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
